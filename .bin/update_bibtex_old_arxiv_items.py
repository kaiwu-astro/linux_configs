#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import json
import os
import re
import sys
from pathlib import Path
from typing import List, Tuple

import requests

ADS_EXPORT_URL = "https://api.adsabs.harvard.edu/v1/export/bibtex"

def split_entries_with_lines(lines: List[str]) -> List[Tuple[int, int, List[str]]]:
    """
    å°† bibtex æ–‡ä»¶æŒ‰æ¡ç›®åˆ’åˆ†ï¼Œå¹¶è¿”å› [(start_line_idx, end_line_idx, entry_lines), ...]
    end_line_idx ä¸º slice æœ«ç«¯ç´¢å¼•ï¼ˆå³ entry åœ¨åŸåˆ—è¡¨ä¸­çš„åˆ‡ç‰‡ lines[start:end]ï¼‰
    """
    entries = []
    start = None
    for idx, line in enumerate(lines):
        if line.lstrip().startswith("@"):
            if start is not None:
                entries.append((start, idx, lines[start:idx]))
            start = idx
    if start is not None:
        entries.append((start, len(lines), lines[start:]))
    return entries


def extract_cite_key(entry_text: str) -> Tuple[str, str]:
    """
    ä» BibTeX å­—ç¬¦ä¸²ä¸­æå– entry ç±»å‹å’Œ cite key
    """
    match = re.match(r'\s*@\s*([A-Za-z]+)\s*{\s*([^,]+)\s*,', entry_text, flags=re.DOTALL)
    if not match:
        raise ValueError("æ— æ³•è§£æ cite key")
    entry_type, cite_key = match.group(1).strip(), match.group(2).strip()
    return entry_type, cite_key


def has_arxiv_journal(entry_text: str) -> bool:
    """
    åˆ¤æ–­æ¡ç›®æ˜¯å¦ä¸º arXiv å¼•ç”¨ï¼šjournal = {arXiv e-prints}
    """
    return bool(re.search(r'journal\s*=\s*[{"]\s*arXiv\s+e-prints\s*["}]?', entry_text, re.IGNORECASE))


def validate_adsurl(entry_text: str) -> bool:
    """
    éªŒè¯ adsurl æ˜¯å¦ç¬¦åˆåŒ…å« abs å’Œ arxiv çš„è¦æ±‚
    """
    return bool(re.search(r'adsurl\s*=\s*[{"]\s*https?://[^}]*abs[^}]*arxiv', entry_text, re.IGNORECASE))


def extract_bibcode(entry_text: str) -> str:
    """
    ä» adsurl ä¸­æå– bibcode
    """
    match = re.search(
        r'adsurl\s*=\s*[{"]\s*https?://ui\.adsabs\.harvard\.edu/abs/([^}"/\s]+)',
        entry_text,
        re.IGNORECASE
    )
    if not match:
        raise ValueError("æœªèƒ½ä» adsurl ä¸­æå– bibcode")
    return match.group(1)


def load_api_token(token_path: Path = Path("~/.ads_api_token").expanduser()) -> str:
    if not token_path.exists():
        raise RuntimeError("æœªæ‰¾åˆ° ~/.ads_api_token æ–‡ä»¶ã€‚")
    with token_path.open("r", encoding="utf-8") as f:
        first_line = f.readline().strip()
    if not first_line:
        raise RuntimeError("~/.ads_api_token æ–‡ä»¶ä¸ºç©ºã€‚")
    return first_line


def fetch_updated_entry(bibcode: str, api_token: str) -> str:
    """
    è°ƒç”¨ ADS Export API è·å–æ›´æ–°åçš„ BibTeX
    """
    headers = {
        "Authorization": f"Bearer {api_token}",
        "Content-Type": "application/json",
    }
    payload = {"bibcode": [bibcode]}
    response = requests.post(
        ADS_EXPORT_URL,
        headers=headers,
        data=json.dumps(payload),
        timeout=30,
    )
    if not response.ok:
        raise RuntimeError(
            f"ADS API è¿”å›é”™è¯¯çŠ¶æ€ç  {response.status_code}: {response.text}"
        )
    data = response.json()
    updated_entry = data.get("export")
    if not updated_entry:
        raise RuntimeError("ADS API è¿”å›ä¸­ç¼ºå¤± 'export' å­—æ®µ")
    return updated_entry


def replace_cite_key(entry_text: str, new_key: str) -> str:
    """
    å°† BibTeX æ¡ç›®çš„ cite key æ›¿æ¢ä¸ºæŒ‡å®šçš„ new_key
    """
    def replacer(match):
        return f"{match.group(1)}{new_key}{match.group(3)}"

    return re.sub(
        r'(@\s*[A-Za-z]+\s*{\s*)([^,]+)(\s*,)',
        replacer,
        entry_text,
        count=1,
        flags=re.DOTALL
    )


def main():
    if len(sys.argv) < 2:
        print("âŒ è¯·æä¾›è¾“å…¥ BibTeX æ–‡ä»¶è·¯å¾„ä½œä¸ºç¬¬ä¸€ä¸ªå‚æ•°", file=sys.stderr)
        sys.exit(1)

    input_bib_path = Path(sys.argv[1]).expanduser()
    if not input_bib_path.exists():
        print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨ï¼š{input_bib_path}", file=sys.stderr)
        sys.exit(1)
    try:
        api_token = load_api_token()
    except RuntimeError as exc:
        print(f"âŒ {exc}è¯·å‚è€ƒ https://github.com/adsabs/adsabs-dev-api?tab=readme-ov-file#access æ·»åŠ  tokenã€‚", file=sys.stderr)
        sys.exit(1)

    with input_bib_path.open("r", encoding="utf-8") as f:
        lines = f.readlines()

    entries = split_entries_with_lines(lines)
    updated_entries: List[str] = []
    updated_count = 0

    print(f"å…±å‘ç° {len(entries)} ä¸ª BibTeX æ¡ç›®ã€‚å¼€å§‹æ£€æŸ¥ arXiv æ¡ç›®...\n")

    for start_idx, end_idx, entry_lines in entries:
        entry_text = "".join(entry_lines)
        try:
            entry_type, cite_key = extract_cite_key(entry_text)
        except ValueError:
            print(f"[â—ï¸ è­¦å‘Š] ç¬¬ {start_idx + 1} è¡Œæ¡ç›®æ— æ³•è§£æ cite keyï¼Œå·²è·³è¿‡ã€‚")
            updated_entries.append(entry_text)
            continue

        if not has_arxiv_journal(entry_text):
            # é arXivï¼Œä¿æŒåŸæ ·
            updated_entries.append(entry_text)
            continue

        print(f"[ä¿¡æ¯] ç¬¬ {start_idx + 1} è¡Œï¼šæ£€æµ‹åˆ° arXiv æ¡ç›® -> cite_key = {cite_key}")

        if not validate_adsurl(entry_text):
            print(f"  [âŒ é”™è¯¯] adsurl å­—æ®µæœªé€šè¿‡éªŒè¯ï¼ˆéœ€è¦åŒ…å« abs ä¸ arxivï¼‰ï¼Œè·³è¿‡ï¼š{cite_key}")
            updated_entries.append(entry_text)
            continue

        try:
            bibcode = extract_bibcode(entry_text)
        except ValueError as exc:
            print(f"  [â—ï¸ è­¦å‘Š] {exc} -> è·³è¿‡ï¼š{cite_key}")
            updated_entries.append(entry_text)
            continue

        print(f"  [ä¿¡æ¯] æå–åˆ° ADS bibcode: {bibcode}")

        try:
            updated_entry = fetch_updated_entry(bibcode, api_token)
        except Exception as exc:
            print(f"  [âŒ å¤±è´¥] ADS API è°ƒç”¨å¤±è´¥ï¼š{exc} -> è·³è¿‡ï¼š{cite_key}")
            updated_entries.append(entry_text)
            continue

        if has_arxiv_journal(updated_entry):
            print(f"  [ğŸ¤ª ä¿¡æ¯] ADS è¿”å›ç»“æœä»ä¸º arXiv æ¡ç›®ï¼Œè·³è¿‡ï¼š{cite_key}")
            updated_entries.append(entry_text)
            continue

        updated_entry = replace_cite_key(updated_entry, cite_key)
        if not updated_entry.endswith("\n"):
            updated_entry += "\n"
        updated_entries.append(updated_entry)
        updated_count += 1
        print(f"  [âœ… æˆåŠŸ] å·²æ›´æ–° {cite_key}\n")

    output_path = input_bib_path.with_stem(input_bib_path.stem + "_updated")
    with output_path.open("w", encoding="utf-8") as f:
        f.write("".join(updated_entries))

    print(f"\nå¤„ç†å®Œæˆï¼Œå…±æ›´æ–° {updated_count} ä¸ª arXiv æ¡ç›®ã€‚")
    print(f"æ›´æ–°åçš„ BibTeX æ–‡ä»¶å·²å†™å…¥ï¼š{output_path}")


if __name__ == "__main__":
    main()